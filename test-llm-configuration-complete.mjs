// test-llm-configuration-complete.mjs - ‚úÖ EXTENSION .mjs OBLIGATOIRE
// Test final complet du projet de configuration LLM Melyia v30
import axios from "axios";

const API_BASE = "https://app-dev.melyia.com/api";

async function testLLMConfigurationComplete() {
  console.log("üöÄ === TEST COMPLET PROJET CONFIGURATION LLM v30 ===\n");

  try {
    // Test 1: Connexion admin
    console.log("üîê √âtape 1: Authentification admin...");
    const loginResponse = await axios.post(`${API_BASE}/auth/login`, {
      email: "brice@melyia.com",
      password: "password",
    });

    if (!loginResponse.data.success) {
      throw new Error("√âchec connexion admin");
    }

    const token = loginResponse.data.token;
    console.log("‚úÖ Authentification admin r√©ussie\n");

    // Test 2: Validation routes API backend
    console.log("üõ†Ô∏è √âtape 2: Validation routes API backend...");

    // GET Configuration
    const getConfigResponse = await axios.get(`${API_BASE}/admin/llm-config`, {
      headers: { Authorization: `Bearer ${token}` },
    });

    if (!getConfigResponse.data.success) {
      throw new Error("√âchec GET configuration");
    }

    const originalConfig = getConfigResponse.data.data;
    console.log("‚úÖ Route GET /api/admin/llm-config fonctionnelle");

    // PUT Configuration
    const testConfigUpdate = {
      temperature: 0.7,
      maxTokens: 75,
    };

    const putConfigResponse = await axios.put(
      `${API_BASE}/admin/llm-config`,
      testConfigUpdate,
      {
        headers: {
          Authorization: `Bearer ${token}`,
          "Content-Type": "application/json",
        },
      }
    );

    if (!putConfigResponse.data.success) {
      throw new Error("√âchec PUT configuration");
    }

    console.log("‚úÖ Route PUT /api/admin/llm-config fonctionnelle");
    console.log("‚úÖ Backend API: 100% op√©rationnel\n");

    // Test 3: Validation int√©gration chatbot dynamique
    console.log("ü§ñ √âtape 3: Validation int√©gration chatbot dynamique...");

    // Connexion patient pour test chatbot
    const patientLoginResponse = await axios.post(`${API_BASE}/auth/login`, {
      email: "patient@melyia.com",
      password: "test123",
    });

    const patientToken = patientLoginResponse.data.token;

    // Test chatbot avec configuration modifi√©e
    const chatResponse = await axios.post(
      `${API_BASE}/chat`,
      {
        message: "Bonjour, j'ai mal aux dents",
        patientId: 1,
      },
      {
        headers: { Authorization: `Bearer ${patientToken}` },
      }
    );

    if (!chatResponse.data.success) {
      throw new Error("√âchec chatbot");
    }

    // V√©rification m√©tadonn√©es dynamiques
    const metadata = chatResponse.data.metadata;
    if (metadata.architecture !== "OLLAMA_DYNAMIC_CONFIG") {
      throw new Error("Architecture dynamique non activ√©e");
    }

    if (metadata.config_used.temperature !== 0.7) {
      throw new Error(
        `Configuration dynamique non appliqu√©e: temp ${metadata.config_used.temperature} vs 0.7 attendu`
      );
    }

    console.log("‚úÖ Chatbot utilise la configuration dynamique");
    console.log(`‚úÖ Architecture: ${metadata.architecture}`);
    console.log(
      `‚úÖ Temp√©rature appliqu√©e: ${metadata.config_used.temperature}`
    );
    console.log(`‚úÖ Max Tokens appliqu√©: ${metadata.config_used.max_tokens}`);
    console.log("‚úÖ Int√©gration dynamique: 100% op√©rationnelle\n");

    // Test 4: Validation interface frontend (simulation)
    console.log("üé® √âtape 4: Validation interface frontend...");

    // Test structure r√©ponse pour frontend
    const frontendConfigResponse = await axios.get(
      `${API_BASE}/admin/llm-config`,
      {
        headers: { Authorization: `Bearer ${token}` },
      }
    );

    const frontendConfig = frontendConfigResponse.data.data;

    // Validation propri√©t√©s camelCase pour frontend
    const requiredProps = [
      "id",
      "modelName",
      "systemPrompt",
      "systemPromptUrgence",
      "temperature",
      "topP",
      "maxTokens",
      "numCtx",
      "keepAliveMinutes",
      "timeoutSeconds",
      "stopSequences",
      "createdAt",
      "updatedAt",
    ];

    const missingProps = requiredProps.filter(
      (prop) => frontendConfig[prop] === undefined
    );

    if (missingProps.length > 0) {
      throw new Error(
        `Propri√©t√©s manquantes pour frontend: ${missingProps.join(", ")}`
      );
    }

    console.log("‚úÖ Structure de donn√©es compatible frontend");
    console.log("‚úÖ Propri√©t√©s camelCase valid√©es");
    console.log("‚úÖ Interface frontend: 100% compatible\n");

    // Test 5: Test modifications temps r√©el bout en bout
    console.log("‚ö° √âtape 5: Test modifications temps r√©el bout en bout...");

    // Modification 1: Interface ‚Üí API ‚Üí Chatbot
    const realtimeConfig1 = {
      temperature: 0.3,
      maxTokens: 30,
    };

    await axios.put(`${API_BASE}/admin/llm-config`, realtimeConfig1, {
      headers: {
        Authorization: `Bearer ${token}`,
        "Content-Type": "application/json",
      },
    });

    // Test chatbot avec nouvelle config
    const chatResponse2 = await axios.post(
      `${API_BASE}/chat`,
      {
        message: "Test config temps r√©el",
        patientId: 1,
      },
      {
        headers: { Authorization: `Bearer ${patientToken}` },
      }
    );

    const metadata2 = chatResponse2.data.metadata;

    if (metadata2.config_used.temperature !== 0.3) {
      throw new Error(
        `Config temps r√©el non appliqu√©e: ${metadata2.config_used.temperature} vs 0.3`
      );
    }

    console.log("‚úÖ Modification interface ‚Üí API ‚Üí Chatbot en temps r√©el");
    console.log(
      `‚úÖ Nouvelle temp√©rature appliqu√©e: ${metadata2.config_used.temperature}`
    );
    console.log("‚úÖ Workflow temps r√©el: 100% fonctionnel\n");

    // Restauration configuration originale
    console.log("üîÑ Restauration configuration originale...");
    await axios.put(`${API_BASE}/admin/llm-config`, originalConfig, {
      headers: {
        Authorization: `Bearer ${token}`,
        "Content-Type": "application/json",
      },
    });
    console.log("‚úÖ Configuration originale restaur√©e\n");

    // R√©sum√© final
    console.log("üéØ === R√âSUM√â COMPLET PROJET LLM CONFIGURATION ===");
    console.log("‚úÖ MICRO-√âTAPE 1: Base de donn√©es (Table llm_settings)");
    console.log(
      "‚úÖ MICRO-√âTAPE 2: Routes API backend (GET/PUT /api/admin/llm-config)"
    );
    console.log(
      "‚úÖ MICRO-√âTAPE 3: Int√©gration dynamique chatbot (OLLAMA_DYNAMIC_CONFIG)"
    );
    console.log(
      "‚úÖ MICRO-√âTAPE 4: Interface admin frontend (Compatible camelCase)"
    );
    console.log("‚úÖ WORKFLOW TEMPS R√âEL: Interface ‚Üí API ‚Üí Chatbot");
    console.log("\nüìä Taux de r√©ussite global: 5/5 micro-√©tapes (100.0%)");
    console.log("\nüéâ PROJET CONFIGURATION LLM 100% TERMIN√â ET OP√âRATIONNEL !");
    console.log("üöÄ Les administrateurs peuvent maintenant :");
    console.log("   ‚Ä¢ Modifier les param√®tres IA via interface web");
    console.log("   ‚Ä¢ Voir les changements appliqu√©s en temps r√©el au chatbot");
    console.log("   ‚Ä¢ Contr√¥ler temp√©rature, tokens, prompts, mod√®les, etc.");
    console.log("   ‚Ä¢ Tout sans acc√®s serveur ni red√©marrage n√©cessaire");
    console.log(
      "\n‚ú® MISSION ACCOMPLIE ! Configuration LLM dynamique active !"
    );
  } catch (error) {
    console.error(
      "‚ùå Erreur lors du test complet:",
      error.response?.data || error.message
    );
    console.log("\nüö® √âCHEC - Projet non compl√®tement fonctionnel");
    return false;
  }

  return true;
}

async function runCompleteTest() {
  const success = await testLLMConfigurationComplete();
  process.exit(success ? 0 : 1);
}

runCompleteTest().catch(console.error);
