# ğŸš€ OPTIMISATIONS CHATBOT - PERFORMANCE SUB-10 SECONDES

## ğŸ“Š SITUATION INITIALE

- **ProblÃ¨me**: Temps de rÃ©ponse > 1 minute (83 secondes observÃ©s)
- **Objectif**: Passer sous les 10 secondes
- **Architecture**: Ollama + llama3.2:3b + Express + React

## âš¡ OPTIMISATIONS IMPLÃ‰MENTÃ‰ES

### 1. **API BACKEND (server.js)**

#### ğŸ”§ Simplification de l'intent detection

```javascript
// AVANT: Classification complexe avec 4 catÃ©gories
// APRÃˆS: Classification binaire urgence/gÃ©nÃ©ral
const messageLower = message.toLowerCase();
let intent = "general";
let isUrgent = false;

if (
  messageLower.includes("urgent") ||
  messageLower.includes("douleur") ||
  messageLower.includes("mal")
) {
  intent = "urgence";
  isUrgent = true;
}
```

#### ğŸ“„ RÃ©duction des documents chargÃ©s

```javascript
// AVANT: LIMIT 5 documents + 800 caractÃ¨res par document
// APRÃˆS: LIMIT 2 documents + 200 caractÃ¨res par document
const documentsQuery = `
  SELECT id, title, content, document_type, file_name, created_at
  FROM patient_documents
  WHERE patient_id = $1 AND processing_status = 'completed'
  ORDER BY created_at DESC
  LIMIT 2  -- RÃ©duit de 5 Ã  2
`;
```

#### ğŸ¯ Prompt ultra-compact

```javascript
// AVANT: Prompt complexe >500 caractÃ¨res avec instructions dÃ©taillÃ©es
// APRÃˆS: Prompt minimal <200 caractÃ¨res
const fullPrompt = `${systemPrompt}

DOSSIER: ${contextPrompt}

QUESTION: ${message}

RÃ©ponds en franÃ§ais, max 150 mots, prÃ©cis et rassurant.

RÃ‰PONSE:`;
```

#### âš™ï¸ Configuration Ollama optimisÃ©e

```javascript
// OPTIMISATIONS CRITIQUES:
{
  model: 'llama3.2:3b',
  keep_alive: "30m",        // 30min au lieu de 24h (Ã©conomie mÃ©moire)
  options: {
    temperature: 0.2,       // Plus dÃ©terministe (0.3 â†’ 0.2)
    top_p: 0.8,             // Plus focalisÃ© (0.9 â†’ 0.8)
    num_predict: 200,       // Limite rÃ©ponse (400 â†’ 200 tokens)
    num_ctx: 1024,          // Contexte rÃ©duit (2048 â†’ 1024)
    stop: ["\n\nQUESTION:", "\n\nDOSSIER:", "RÃ‰PONSE:", "\n---"]
  }
},
timeout: 15000  // 15s au lieu de 5min
```

#### ğŸ’¾ Sauvegarde asynchrone

```javascript
// AVANT: Sauvegarde bloquante avant la rÃ©ponse
// APRÃˆS: Sauvegarde non-bloquante
setImmediate(async () => {
  try {
    await pool.query(/* INSERT conversation */);
  } catch (saveError) {
    console.error("âš ï¸ Erreur sauvegarde async:", saveError.message);
  }
});
```

### 2. **KEEP-ALIVE OPTIMISÃ‰**

#### ğŸ”„ Warm-up intelligent

```javascript
// OPTIMISATIONS:
- Prompt minimal: "OK" au lieu de "Hello"
- num_predict: 1 (un seul token)
- timeout: 3s au lieu de 5s
- keep_alive: 30m optimisÃ©
- Retry intelligent avec 3 tentatives
- FrÃ©quence augmentÃ©e: 15min au lieu de 1h
```

### 3. **ARCHITECTURE FAST_MODE**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚    Backend       â”‚    â”‚     Ollama      â”‚
â”‚   React         â”‚â”€â”€â”€â”€â”‚    Express       â”‚â”€â”€â”€â”€â”‚   llama3.2:3b   â”‚
â”‚                 â”‚    â”‚                  â”‚    â”‚                 â”‚
â”‚ â€¢ Timeout 15s   â”‚    â”‚ â€¢ Prompt compact â”‚    â”‚ â€¢ keep_alive 30mâ”‚
â”‚ â€¢ UI optimisÃ©e  â”‚    â”‚ â€¢ Docs limitÃ©s   â”‚    â”‚ â€¢ ctx rÃ©duit    â”‚
â”‚                 â”‚    â”‚ â€¢ Save async     â”‚    â”‚ â€¢ stop tokens   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ˆ GAINS DE PERFORMANCE ATTENDUS

### ğŸ¯ Temps de rÃ©ponse cibles:

- **Excellent**: â‰¤ 3 secondes (utilisateur ne remarque pas l'attente)
- **Acceptable**: â‰¤ 10 secondes (objectif projet)
- **ProblÃ©matique**: > 10 secondes (nÃ©cessite optimisation supplÃ©mentaire)

### âš¡ Optimisations spÃ©cifiques:

1. **Prompt size**: 500+ caractÃ¨res â†’ ~150 caractÃ¨res (**-70%**)
2. **Documents**: 5 docs Ã— 800 chars â†’ 2 docs Ã— 200 chars (**-75%**)
3. **Tokens gÃ©nÃ©ration**: 400 â†’ 200 tokens (**-50%**)
4. **Contexte**: 2048 â†’ 1024 tokens (**-50%**)
5. **Timeout**: 300s â†’ 15s (**-95%**)

## ğŸ› ï¸ SCRIPTS DE TEST

### Test de performance complet:

```bash
node test-chat-performance.js
```

### Test optimisation Ollama:

```bash
node optimize-ollama.js
```

### DÃ©ploiement optimisations:

```bash
node deploy-optimizations.js
```

## ğŸ“‹ MONITORING POST-DÃ‰PLOIEMENT

### ğŸ” MÃ©triques Ã  surveiller:

1. **Temps de rÃ©ponse API chat** (objectif < 10s)
2. **Temps traitement Ollama** (doit Ãªtre la majoritÃ© du temps total)
3. **Taux de succÃ¨s des requÃªtes** (>95%)
4. **Utilisation mÃ©moire serveur** (modÃ¨le llama3.2:3b = ~4GB)
5. **Charge CPU pendant gÃ©nÃ©ration**

### ğŸ“Š Commandes de monitoring:

```bash
# Logs temps rÃ©el
ssh ubuntu@51.91.145.255 "pm2 logs auth-dev --lines 50"

# Statut systÃ¨me
ssh ubuntu@51.91.145.255 "free -h && htop"

# Test Ollama direct
curl http://51.91.145.255:11434/api/version
```

## ğŸš¨ PLAN DE ROLLBACK

### Si performances dÃ©gradÃ©es:

```bash
# 1. Restaurer backup
ssh ubuntu@51.91.145.255 "cd /var/www/melyia/server/backend && cp server.js.backup.* server.js"

# 2. RedÃ©marrer PM2
ssh ubuntu@51.91.145.255 "pm2 restart auth-dev"

# 3. VÃ©rifier service
curl https://app-dev.melyia.com/api/health
```

## ğŸ”® OPTIMISATIONS FUTURES POSSIBLES

### ğŸ§  Si performances encore insuffisantes:

1. **ModÃ¨le plus lÃ©ger**:

   - Tester `llama3.2:1b` (plus rapide mais moins prÃ©cis)
   - Ou modÃ¨les spÃ©cialisÃ©s mÃ©dicaux plus petits

2. **Cache intelligent**:

   - Cache des rÃ©ponses frÃ©quentes
   - PrÃ©-calcul des contextes patients

3. **Load balancing**:

   - Plusieurs instances Ollama
   - Queue de requÃªtes avec prioritÃ©s

4. **Hardware**:
   - GPU dÃ©diÃ© pour l'infÃ©rence
   - Plus de RAM pour keep-alive permanent

## âœ… VALIDATION DU SUCCÃˆS

### CritÃ¨res de succÃ¨s:

- [ ] Temps moyen < 10 secondes
- [ ] 95% des requÃªtes sous 15 secondes
- [ ] Aucune dÃ©gradation qualitÃ© des rÃ©ponses
- [ ] SystÃ¨me stable sous charge normale
- [ ] Logs sans erreurs critiques

### Tests d'acceptation:

1. **Test utilisateur final**: Dialogue naturel via interface web
2. **Test de charge**: 5 utilisateurs simultanÃ©s
3. **Test de robustesse**: 100 requÃªtes consÃ©cutives
4. **Test edge cases**: Prompts trÃ¨s longs, caractÃ¨res spÃ©ciaux

---

**Date de dÃ©ploiement**: [Ã€ complÃ©ter]  
**Version**: v2.0 - FAST_MODE  
**Responsable**: Ã‰quipe dev Melyia
