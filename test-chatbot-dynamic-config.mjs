// test-chatbot-dynamic-config.mjs - Test intÃ©gration dynamique LLM v30
import axios from "axios";

const API_BASE = "https://app-dev.melyia.com/api";

// Couleurs pour les logs
const colors = {
  green: "\x1b[32m",
  red: "\x1b[31m",
  yellow: "\x1b[33m",
  blue: "\x1b[34m",
  cyan: "\x1b[36m",
  reset: "\x1b[0m",
};

function log(color, message) {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

async function loginPatient() {
  try {
    log("blue", "ğŸ” Connexion patient pour test chatbot...");

    const response = await axios.post(`${API_BASE}/auth/login`, {
      email: "patient@melyia.com",
      password: "test123",
    });

    if (response.data.success) {
      log("green", "âœ… Connexion patient rÃ©ussie");
      return {
        token: response.data.token,
        userId: response.data.user.id,
      };
    }

    throw new Error("Login failed: " + JSON.stringify(response.data));
  } catch (error) {
    log("red", "âŒ Erreur connexion patient:");
    console.error(error.response?.data || error.message);
    return null;
  }
}

async function loginAdmin() {
  try {
    log("blue", "ğŸ” Connexion admin pour modifier config...");

    const response = await axios.post(`${API_BASE}/auth/login`, {
      email: "brice@melyia.com",
      password: "password",
    });

    if (response.data.success) {
      log("green", "âœ… Connexion admin rÃ©ussie");
      return response.data.token;
    }

    throw new Error("Login failed: " + JSON.stringify(response.data));
  } catch (error) {
    log("red", "âŒ Erreur connexion admin:");
    console.error(error.response?.data || error.message);
    return null;
  }
}

async function getCurrentLLMConfig(adminToken) {
  try {
    const response = await axios.get(`${API_BASE}/admin/llm-config`, {
      headers: { Authorization: `Bearer ${adminToken}` },
    });

    if (response.data.success) {
      return response.data.data;
    }
    return null;
  } catch (error) {
    console.error(
      "Erreur rÃ©cupÃ©ration config:",
      error.response?.data || error.message
    );
    return null;
  }
}

async function updateLLMConfig(adminToken, newConfig) {
  try {
    const response = await axios.put(
      `${API_BASE}/admin/llm-config`,
      newConfig,
      {
        headers: { Authorization: `Bearer ${adminToken}` },
      }
    );

    if (response.data.success) {
      return response.data.data;
    }
    return null;
  } catch (error) {
    console.error(
      "Erreur mise Ã  jour config:",
      error.response?.data || error.message
    );
    return null;
  }
}

async function testChatWithConfig(
  patientToken,
  patientId,
  configName,
  expectedConfig
) {
  try {
    log("cyan", `\nğŸ¤– Test chatbot avec configuration "${configName}"...`);

    const message = "Bonjour, j'ai une petite question sur l'hygiÃ¨ne dentaire.";

    const startTime = Date.now();
    const response = await axios.post(
      `${API_BASE}/chat`,
      {
        message: message,
        patientId: patientId,
      },
      {
        headers: { Authorization: `Bearer ${patientToken}` },
        timeout: 60000, // 60 secondes
      }
    );

    const responseTime = Date.now() - startTime;

    if (response.data.success) {
      log("green", `âœ… Chatbot rÃ©pondu en ${responseTime}ms`);

      const metadata = response.data.metadata;
      console.log("ğŸ“‹ MÃ©tadonnÃ©es de rÃ©ponse:");
      console.log(`   â€¢ Architecture: ${metadata.architecture}`);
      console.log(`   â€¢ ModÃ¨le: ${metadata.model}`);
      console.log(`   â€¢ Config utilisÃ©e:`);
      console.log(`     - TempÃ©rature: ${metadata.configUsed.temperature}`);
      console.log(`     - Max Tokens: ${metadata.configUsed.maxTokens}`);
      console.log(`     - Keep Alive: ${metadata.configUsed.keepAlive}`);
      console.log(`     - Timeout: ${metadata.configUsed.timeout}`);
      console.log(`   â€¢ Temps traitement: ${metadata.processingTime}`);
      console.log(`   â€¢ Intent dÃ©tectÃ©: ${metadata.intent}`);

      // VÃ©rification que la config dynamique est bien utilisÃ©e
      const configValid =
        metadata.architecture === "OLLAMA_DYNAMIC_CONFIG" &&
        metadata.configUsed.temperature === expectedConfig.temperature &&
        metadata.configUsed.maxTokens === expectedConfig.maxTokens;

      if (configValid) {
        log("green", "âœ… Configuration dynamique correctement appliquÃ©e");
        return true;
      } else {
        log("red", "âŒ Configuration dynamique non appliquÃ©e correctement");
        console.log("   Attendu:", expectedConfig);
        console.log("   ReÃ§u:", metadata.configUsed);
        return false;
      }
    } else {
      log("red", "âŒ Erreur chatbot:", response.data.error);
      return false;
    }
  } catch (error) {
    log("red", `âŒ Erreur test chatbot (${configName}):`);
    console.error(error.response?.data || error.message);
    return false;
  }
}

async function runDynamicConfigTests() {
  console.log("ğŸš€ === TEST INTÃ‰GRATION DYNAMIQUE LLM CHATBOT v30 ===\n");

  // Connexions
  const adminToken = await loginAdmin();
  const patientAuth = await loginPatient();

  if (!adminToken || !patientAuth) {
    log("red", "âŒ Impossible de continuer sans authentification");
    return;
  }

  const { token: patientToken, userId: patientId } = patientAuth;

  // RÃ©cupÃ©rer config actuelle
  log("blue", "\nğŸ“‹ RÃ©cupÃ©ration de la configuration actuelle...");
  const originalConfig = await getCurrentLLMConfig(adminToken);

  if (!originalConfig) {
    log("red", "âŒ Impossible de rÃ©cupÃ©rer la configuration actuelle");
    return;
  }

  console.log("ğŸ”§ Configuration originale:");
  console.log(`   â€¢ TempÃ©rature: ${originalConfig.temperature}`);
  console.log(`   â€¢ Max Tokens: ${originalConfig.maxTokens}`);
  console.log(`   â€¢ Model: ${originalConfig.modelName}`);

  const results = {
    configOriginal: false,
    configModified1: false,
    configModified2: false,
    configRestored: false,
  };

  // Test 1: Chatbot avec config originale
  results.configOriginal = await testChatWithConfig(
    patientToken,
    patientId,
    "Configuration Originale",
    {
      temperature: originalConfig.temperature,
      maxTokens: originalConfig.maxTokens,
    }
  );

  // Test 2: Modifier config et tester
  log(
    "blue",
    "\nğŸ”§ Modification de la configuration (tempÃ©rature + tokens)..."
  );
  const config1 = {
    temperature: 0.8, // Plus crÃ©atif
    maxTokens: 150, // Plus long
  };

  const updated1 = await updateLLMConfig(adminToken, config1);
  if (updated1) {
    log(
      "green",
      `âœ… Config modifiÃ©e - Temp: ${config1.temperature}, Tokens: ${config1.maxTokens}`
    );
    await new Promise((resolve) => setTimeout(resolve, 2000)); // Attendre 2s

    results.configModified1 = await testChatWithConfig(
      patientToken,
      patientId,
      "Configuration CrÃ©ative",
      config1
    );
  }

  // Test 3: Autre modification
  log(
    "blue",
    "\nğŸ”§ DeuxiÃ¨me modification (tempÃ©rature basse + tokens courts)..."
  );
  const config2 = {
    temperature: 0.1, // Plus dÃ©terministe
    maxTokens: 50, // Plus court
  };

  const updated2 = await updateLLMConfig(adminToken, config2);
  if (updated2) {
    log(
      "green",
      `âœ… Config modifiÃ©e - Temp: ${config2.temperature}, Tokens: ${config2.maxTokens}`
    );
    await new Promise((resolve) => setTimeout(resolve, 2000)); // Attendre 2s

    results.configModified2 = await testChatWithConfig(
      patientToken,
      patientId,
      "Configuration DÃ©terministe",
      config2
    );
  }

  // Test 4: Restaurer config originale
  log("blue", "\nğŸ”„ Restauration de la configuration originale...");
  const restored = await updateLLMConfig(adminToken, {
    temperature: originalConfig.temperature,
    maxTokens: originalConfig.maxTokens,
  });

  if (restored) {
    log("green", "âœ… Configuration restaurÃ©e");
    await new Promise((resolve) => setTimeout(resolve, 2000)); // Attendre 2s

    results.configRestored = await testChatWithConfig(
      patientToken,
      patientId,
      "Configuration RestaurÃ©e",
      {
        temperature: originalConfig.temperature,
        maxTokens: originalConfig.maxTokens,
      }
    );
  }

  // RÃ©sumÃ© final
  console.log("\nğŸ¯ === RÃ‰SUMÃ‰ DES TESTS DYNAMIQUES ===");
  Object.entries(results).forEach(([test, success]) => {
    const status = success ? "âœ… PASS" : "âŒ FAIL";
    console.log(`${status} ${test}`);
  });

  const totalTests = Object.keys(results).length;
  const passedTests = Object.values(results).filter(Boolean).length;
  const successRate = ((passedTests / totalTests) * 100).toFixed(1);

  console.log(
    `\nğŸ“Š Taux de rÃ©ussite: ${passedTests}/${totalTests} (${successRate}%)`
  );

  if (passedTests === totalTests) {
    log("green", "\nğŸ‰ TOUS LES TESTS DYNAMIQUES PASSÃ‰S !");
    log("green", "ğŸš€ L'intÃ©gration dynamique LLM est 100% opÃ©rationnelle !");
    log(
      "cyan",
      "âœ¨ Le chatbot utilise maintenant les paramÃ¨tres configurables en temps rÃ©el !"
    );
  } else {
    log("red", `\nâš ï¸  ${totalTests - passedTests} test(s) Ã©chouÃ©(s)`);
    log("yellow", "ğŸ”§ VÃ©rification de l'intÃ©gration nÃ©cessaire");
  }

  return results;
}

// ExÃ©cution des tests
runDynamicConfigTests().catch(console.error);
